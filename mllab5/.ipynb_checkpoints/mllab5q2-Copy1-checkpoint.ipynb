{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e94f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('car_evaluation.csv')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "data.rename(columns={'vhigh': 'buyprice', 'vhigh.1': 'maintainprice', '2': 'doors', '2.1': 'persons', 'small': 'luggagesize', 'low': 'safety', 'unacc':'rating'}, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6994a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    if data[column].dtype =='object':\n",
    "        unique_values = data[column].unique()\n",
    "        print(f\"Column '{column}' has {len(unique_values)} unique values: \" )\n",
    "        print(unique_values)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        min_value = data[column].min()\n",
    "        max_value = data[column].max()\n",
    "        print(f\"Column '{column}' has values in range from {min_value} to {max_value}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    print(data[column].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e6864d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(instance1, instance2):\n",
    "    return sum(val1 != val2 for val1, val2 in zip(instance1, instance2))\n",
    "\n",
    "def knn(train_data, test_instance, k):\n",
    "    distances = []\n",
    "\n",
    "    for _, train_instance in train_data.iterrows():\n",
    "        dist = hamming_distance(train_instance[:-1], test_instance)\n",
    "        distances.append((train_instance, dist))\n",
    "\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "\n",
    "    neighbors = [dist[0] for dist in distances[:k]]\n",
    "\n",
    "    class_counts = {}\n",
    "    for neighbor in neighbors:\n",
    "        label = neighbor['rating']\n",
    "        if label in class_counts:\n",
    "            class_counts[label] += 1\n",
    "        else:\n",
    "            class_counts[label] = 1\n",
    "\n",
    "    predicted_class = max(class_counts, key=class_counts.get)\n",
    "\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9243cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_accuracy = 0.0\n",
    "best_k = 0\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for k in range(1, 11):\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_data, test_data = data.iloc[train_index], data.iloc[test_index]\n",
    "        \n",
    "        predictions = []\n",
    "\n",
    "        for _, test_instance in test_data.iterrows():\n",
    "            predicted_class = knn(train_data, test_instance, k)\n",
    "            predictions.append(predicted_class)\n",
    "\n",
    "        true_labels = test_data['rating']\n",
    "        accuracy = accuracy_score(true_labels, predictions)\n",
    "        fold_accuracies.append(accuracy)\n",
    "\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    accuracies.append(avg_accuracy)\n",
    "    \n",
    "    if avg_accuracy > best_accuracy:\n",
    "        best_accuracy = avg_accuracy\n",
    "        best_k = k\n",
    "\n",
    "print(\"Best accuracy:\", best_accuracy)\n",
    "print(f\"Best k for the model is: {best_k}\")\n",
    "print(f\"Best accuracy of the model for k={best_k} is: {best_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be74e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b8a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3bd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab7eb38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808e05c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3f835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2848bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c7269b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb72f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243caa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "\n",
    "num_folds = 5\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    train_data, test_data = data.iloc[train_index], data.iloc[test_index]\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for _, test_instance in test_data.iterrows():\n",
    "        predicted_class = knn(train_data, test_instance, k)\n",
    "        predictions.append(predicted_class)\n",
    "\n",
    "    true_labels = test_data['rating']\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "std_accuracy = np.std(accuracy_scores)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy*100} %\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(instance1, instance2):\n",
    "    return sum(val1 != val2 for val1, val2 in zip(instance1, instance2))\n",
    "\n",
    "def knn(train_data, test_instance, k):\n",
    "    distances = []\n",
    "\n",
    "    for _, train_instance in train_data.iterrows():\n",
    "        dist = hamming_distance(train_instance[:-1], test_instance)\n",
    "        distances.append((train_instance, dist))\n",
    "\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "\n",
    "    neighbors = [dist[0] for dist in distances[:k]]\n",
    "\n",
    "    class_counts = {}\n",
    "    for neighbor in neighbors:\n",
    "        label = neighbor['rating']\n",
    "        if label in class_counts:\n",
    "            class_counts[label] += 1\n",
    "        else:\n",
    "            class_counts[label] = 1\n",
    "\n",
    "    predicted_class = max(class_counts, key=class_counts.get)\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "k = 3  \n",
    "num_folds = 5\n",
    "validation_size = 0.10\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for fold in range(num_folds):\n",
    "    train_data, test_data = train_test_split(data, test_size=validation_size)\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for _, test_instance in test_data.iterrows():\n",
    "        predicted_class = knn(train_data, test_instance[:-1], k)\n",
    "        actual_class = test_instance['rating']\n",
    "\n",
    "        if predicted_class == actual_class:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / len(test_data)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Accuracy for Fold {fold + 1}: {accuracy* 100:.2f} %\")\n",
    "\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "max_accuracy = max(accuracies)\n",
    "print(f\"Mean Accuracy over {num_folds}-fold cross-validation: {mean_accuracy*100:.2f} %\")\n",
    "print(f\"\\n\\nMaximum Accuracy among all folds: {max_accuracy*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df096bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdacee95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
